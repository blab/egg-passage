Building DAG of jobs...
Using shell: /anaconda2/envs/py3/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	download_all
	1	download_sequences
	1	parse
	3

[Wed Feb 27 15:37:55 2019]
Job 5: Downloading sequences from fauna

[Wed Feb 27 15:39:58 2019]
Finished job 5.
1 of 3 steps (33%) done

[Wed Feb 27 15:39:58 2019]
Job 8: Parsing fasta into sequences and metadata

[Wed Feb 27 15:40:05 2019]
Finished job 8.
2 of 3 steps (67%) done

[Wed Feb 27 15:40:05 2019]
localrule download_all:
    input: data/who_h3n2_cell_hi_titers.tsv, data/who_h3n2_cell_fra_titers.tsv, data/who_h3n2_egg_hi_titers.tsv, data/who_h3n2_egg_fra_titers.tsv, data/h3n2_ha.fasta, data/who_h3n2_concat_hi_titers.tsv, data/who_h3n2_concat_fra_titers.tsv, results/metadata_h3n2_ha.tsv
    jobid: 0

[Wed Feb 27 15:40:05 2019]
Finished job 0.
3 of 3 steps (100%) done
Complete log: /Users/katekistler/nextstrain/egg-passage/.snakemake/log/2019-02-27T153754.276359.snakemake.log
