Building DAG of jobs...
Using shell: /anaconda2/envs/py3/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	download_all
	1	download_sequences
	4	download_titers
	6

[Wed Feb 27 11:24:42 2019]
Job 1: Downloading titers from fauna: h3n2, hi, who

[Wed Feb 27 11:25:36 2019]
Finished job 1.
1 of 6 steps (17%) done

[Wed Feb 27 11:25:36 2019]
Job 5: Downloading sequences from fauna

[Wed Feb 27 11:27:46 2019]
Finished job 5.
2 of 6 steps (33%) done

[Wed Feb 27 11:27:46 2019]
Job 3: Downloading titers from fauna: h3n2, hi, who

[Wed Feb 27 11:28:11 2019]
Finished job 3.
3 of 6 steps (50%) done

[Wed Feb 27 11:28:11 2019]
Job 4: Downloading titers from fauna: h3n2, fra, who

[Wed Feb 27 11:28:29 2019]
Finished job 4.
4 of 6 steps (67%) done

[Wed Feb 27 11:28:29 2019]
Job 2: Downloading titers from fauna: h3n2, fra, who

[Wed Feb 27 11:28:48 2019]
Finished job 2.
5 of 6 steps (83%) done

[Wed Feb 27 11:28:48 2019]
localrule download_all:
    input: data/who_h3n2_cell_hi_titers.tsv, data/who_h3n2_cell_fra_titers.tsv, data/who_h3n2_egg_hi_titers.tsv, data/who_h3n2_egg_fra_titers.tsv, data/h3n2_ha.fasta
    jobid: 0

[Wed Feb 27 11:28:48 2019]
Finished job 0.
6 of 6 steps (100%) done
Complete log: /Users/katekistler/nextstrain/egg-passage/.snakemake/log/2019-02-27T112440.359753.snakemake.log
